{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69238684-0086-4bce-803f-9ec422a6b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text in lowercase with removed punctuation is\n",
      "  one of my favorite topics is technology especially how it shapes our everyday lives\n",
      "it’s fascinating to see how innovations like artificial intelligence smart devices and cloud computing\n",
      "have transformed the way we communicate work and even relax from voicecontrolled assistants that manage\n",
      "our schedules to wearable tech that tracks our health in real time technology is making life more efficient\n",
      "and connected i’m especially intrigued by how ai is being used in creative fields like music composition\n",
      "storytelling and design\n",
      "\n",
      "Word tokenization\n",
      " ['one', 'of', 'my', 'favorite', 'topics', 'is', 'technology', 'especially', 'how', 'it', 'shapes', 'our', 'everyday', 'lives', 'it', '’', 's', 'fascinating', 'to', 'see', 'how', 'innovations', 'like', 'artificial', 'intelligence', 'smart', 'devices', 'and', 'cloud', 'computing', 'have', 'transformed', 'the', 'way', 'we', 'communicate', 'work', 'and', 'even', 'relax', 'from', 'voicecontrolled', 'assistants', 'that', 'manage', 'our', 'schedules', 'to', 'wearable', 'tech', 'that', 'tracks', 'our', 'health', 'in', 'real', 'time', 'technology', 'is', 'making', 'life', 'more', 'efficient', 'and', 'connected', 'i', '’', 'm', 'especially', 'intrigued', 'by', 'how', 'ai', 'is', 'being', 'used', 'in', 'creative', 'fields', 'like', 'music', 'composition', 'storytelling', 'and', 'design']\n",
      "\n",
      "Sentence tokenization\n",
      " [' One of my favorite topics is technology, especially how it shapes our everyday lives.', 'It’s fascinating to see how innovations like artificial intelligence, smart devices, and cloud computing\\nhave transformed the way we communicate, work, and even relax.', 'From voice-controlled assistants that manage\\nour schedules to wearable tech that tracks our health in real time, technology is making life more efficient\\nand connected.', 'I’m especially intrigued by how AI is being used in creative fields like music composition,\\nstorytelling, and design']\n",
      "\n",
      "Text after removing stop words is\n",
      " ['one', 'favorite', 'topics', 'technology', 'especially', 'shapes', 'everyday', 'lives', '’', 'fascinating', 'see', 'innovations', 'like', 'artificial', 'intelligence', 'smart', 'devices', 'cloud', 'computing', 'transformed', 'way', 'communicate', 'work', 'even', 'relax', 'voicecontrolled', 'assistants', 'manage', 'schedules', 'wearable', 'tech', 'tracks', 'health', 'real', 'time', 'technology', 'making', 'life', 'efficient', 'connected', '’', 'especially', 'intrigued', 'ai', 'used', 'creative', 'fields', 'like', 'music', 'composition', 'storytelling', 'design']\n",
      "\n",
      "Word Frequency Counts\n",
      "\n",
      "one: 1\n",
      "favorite: 1\n",
      "topics: 1\n",
      "technology: 2\n",
      "especially: 2\n",
      "shapes: 1\n",
      "everyday: 1\n",
      "lives: 1\n",
      "’: 2\n",
      "fascinating: 1\n",
      "see: 1\n",
      "innovations: 1\n",
      "like: 2\n",
      "artificial: 1\n",
      "intelligence: 1\n",
      "smart: 1\n",
      "devices: 1\n",
      "cloud: 1\n",
      "computing: 1\n",
      "transformed: 1\n",
      "way: 1\n",
      "communicate: 1\n",
      "work: 1\n",
      "even: 1\n",
      "relax: 1\n",
      "voicecontrolled: 1\n",
      "assistants: 1\n",
      "manage: 1\n",
      "schedules: 1\n",
      "wearable: 1\n",
      "tech: 1\n",
      "tracks: 1\n",
      "health: 1\n",
      "real: 1\n",
      "time: 1\n",
      "making: 1\n",
      "life: 1\n",
      "efficient: 1\n",
      "connected: 1\n",
      "intrigued: 1\n",
      "ai: 1\n",
      "used: 1\n",
      "creative: 1\n",
      "fields: 1\n",
      "music: 1\n",
      "composition: 1\n",
      "storytelling: 1\n",
      "design: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk;\n",
    "import string;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize;\n",
    "from nltk.probability import FreqDist;\n",
    "nltk.download('punkt');\n",
    "nltk.download('stopwords');\n",
    "\n",
    "paragraph = \"\"\"One of my favorite topics is technology, especially how it shapes our everyday lives.\n",
    "It’s fascinating to see how innovations like artificial intelligence, smart devices, and cloud computing\n",
    "have transformed the way we communicate, work, and even relax. From voice-controlled assistants that manage\n",
    "our schedules to wearable tech that tracks our health in real time, technology is making life more efficient\n",
    "and connected. I’m especially intrigued by how AI is being used in creative fields like music composition,\n",
    "storytelling, and design\"\"\";\n",
    "\n",
    "text_lower = paragraph.lower();\n",
    "text_clean = text_lower.translate(str.maketrans('', '', string.punctuation));\n",
    "print(\"Text in lowercase with removed punctuation is\\n\",text_clean);\n",
    "\n",
    "words = word_tokenize(text_clean);\n",
    "print(\"\\nWord tokenization\\n\",words);\n",
    "sentences = sent_tokenize(paragraph);\n",
    "print(\"\\nSentence tokenization\\n\",sentences);\n",
    "\n",
    "stop_words = set(stopwords.words('english'));\n",
    "filtered_words = [word for word in words if word not in stop_words];\n",
    "print(\"\\nText after removing stop words is\\n\",filtered_words);\n",
    "\n",
    "freq_dist = FreqDist(filtered_words)\n",
    "print(\"\\nWord Frequency Counts\\n\");\n",
    "for word, freq in freq_dist.items():\n",
    "    print(f\"{word}: {freq}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6e6463-0762-4c82-95cd-94fdbfc8e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original       Porter         Lancaster      Lemmatized     \n",
      "------------------------------------------------------------\n",
      "one            one            on             one            \n",
      "favorite       favorit        favorit        favorite       \n",
      "topics         topic          top            topic          \n",
      "technology     technolog      technolog      technology     \n",
      "especially     especi         espec          especially     \n",
      "shapes         shape          shap           shape          \n",
      "everyday       everyday       everyday       everyday       \n",
      "lives          live           liv            life           \n",
      "’              ’              ’              ’              \n",
      "fascinating    fascin         fascin         fascinating    \n",
      "see            see            see            see            \n",
      "innovations    innov          innov          innovation     \n",
      "like           like           lik            like           \n",
      "artificial     artifici       art            artificial     \n",
      "intelligence   intellig       intellig       intelligence   \n",
      "smart          smart          smart          smart          \n",
      "devices        devic          dev            device         \n",
      "cloud          cloud          cloud          cloud          \n",
      "computing      comput         comput         computing      \n",
      "transformed    transform      transform      transformed    \n",
      "way            way            way            way            \n",
      "communicate    commun         commun         communicate    \n",
      "work           work           work           work           \n",
      "even           even           ev             even           \n",
      "relax          relax          relax          relax          \n",
      "voicecontrolledvoicecontrol   voicecontrol   voicecontrolled\n",
      "assistants     assist         assist         assistant      \n",
      "manage         manag          man            manage         \n",
      "schedules      schedul        schedules      schedule       \n",
      "wearable       wearabl        wear           wearable       \n",
      "tech           tech           tech           tech           \n",
      "tracks         track          track          track          \n",
      "health         health         heal           health         \n",
      "real           real           real           real           \n",
      "time           time           tim            time           \n",
      "technology     technolog      technolog      technology     \n",
      "making         make           mak            making         \n",
      "life           life           lif            life           \n",
      "efficient      effici         efficy         efficient      \n",
      "connected      connect        connect        connected      \n",
      "’              ’              ’              ’              \n",
      "especially     especi         espec          especially     \n",
      "intrigued      intrigu        intrigu        intrigued      \n",
      "ai             ai             ai             ai             \n",
      "used           use            us             used           \n",
      "creative       creativ        cre            creative       \n",
      "fields         field          field          field          \n",
      "like           like           lik            like           \n",
      "music          music          mus            music          \n",
      "composition    composit       composit       composition    \n",
      "storytelling   storytel       storytel       storytelling   \n",
      "design         design         design         design         \n"
     ]
    }
   ],
   "source": [
    "import nltk;\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer;\n",
    "from nltk.corpus import wordnet;\n",
    "nltk.download('wordnet');\n",
    "nltk.download('omw-1.4');\n",
    "\n",
    "filtered_words = ['one', 'favorite', 'topics', 'technology', 'especially', 'shapes', 'everyday', 'lives', '’', 'fascinating', 'see', 'innovations', 'like', 'artificial', 'intelligence', 'smart', 'devices', 'cloud', 'computing', 'transformed', 'way', 'communicate', 'work', 'even', 'relax', 'voicecontrolled', 'assistants', 'manage', 'schedules', 'wearable', 'tech', 'tracks', 'health', 'real', 'time', 'technology', 'making', 'life', 'efficient', 'connected', '’', 'especially', 'intrigued', 'ai', 'used', 'creative', 'fields', 'like', 'music', 'composition', 'storytelling', 'design'];\n",
    "porter = PorterStemmer();\n",
    "lancaster = LancasterStemmer();\n",
    "lemmatizer = WordNetLemmatizer();\n",
    "print(f\"{'Original':<15}{'Porter':<15}{'Lancaster':<15}{'Lemmatized':<15}\");\n",
    "print(\"-\" * 60);\n",
    "for word in filtered_words:\n",
    "    porter_stem = porter.stem(word);\n",
    "    lancaster_stem = lancaster.stem(word);\n",
    "    lemmatized = lemmatizer.lemmatize(word);\n",
    "    print(f\"{word:<15}{porter_stem:<15}{lancaster_stem:<15}{lemmatized:<15}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b52cf2a-7a92-4552-b920-eb01e002f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words with more than 5 letters are\n",
      " ['favorite', 'topics', 'technology', 'especially', 'shapes', 'everyday', 'fascinating', 'innovations', 'artificial', 'intelligence', 'devices', 'computing', 'transformed', 'communicate', 'controlled', 'assistants', 'manage', 'schedules', 'wearable', 'tracks', 'health', 'technology', 'making', 'efficient', 'connected', 'especially', 'intrigued', 'creative', 'fields', 'composition', 'storytelling', 'design']\n",
      "\n",
      "All numbers in text are\n",
      " []\n",
      "\n",
      "All capitalized words are\n",
      " ['One', 'It', 'From']\n",
      "\n",
      "Words containing only alphabets (removing digits and special character)\n",
      " ['One', 'of', 'my', 'favorite', 'topics', 'is', 'technology', 'especially', 'how', 'it', 'shapes', 'our', 'everyday', 'lives', 'It', 's', 'fascinating', 'to', 'see', 'how', 'innovations', 'like', 'artificial', 'intelligence', 'smart', 'devices', 'and', 'cloud', 'computing', 'have', 'transformed', 'the', 'way', 'we', 'communicate', 'work', 'and', 'even', 'relax', 'From', 'voice', 'controlled', 'assistants', 'that', 'manage', 'our', 'schedules', 'to', 'wearable', 'tech', 'that', 'tracks', 'our', 'health', 'in', 'real', 'time', 'technology', 'is', 'making', 'life', 'more', 'efficient', 'and', 'connected', 'I', 'm', 'especially', 'intrigued', 'by', 'how', 'AI', 'is', 'being', 'used', 'in', 'creative', 'fields', 'like', 'music', 'composition', 'storytelling', 'and', 'design']\n",
      "\n",
      "All words starting with a vowel are\n",
      " ['One', 'of', 'is', 'especially', 'it', 'our', 'everyday', 'It', 'innovations', 'artificial', 'intelligence', 'and', 'and', 'even', 'assistants', 'our', 'our', 'in', 'is', 'efficient', 'and', 'I', 'especially', 'intrigued', 'AI', 'is', 'used', 'in', 'and']\n"
     ]
    }
   ],
   "source": [
    "import re;\n",
    "paragraph = \"\"\"One of my favorite topics is technology, especially how it shapes our everyday lives.\n",
    "It’s fascinating to see how innovations like artificial intelligence, smart devices, and cloud computing\n",
    "have transformed the way we communicate, work, and even relax. From voice-controlled assistants that manage\n",
    "our schedules to wearable tech that tracks our health in real time, technology is making life more efficient\n",
    "and connected. I’m especially intrigued by how AI is being used in creative fields like music composition,\n",
    "storytelling, and design.\"\"\";\n",
    "\n",
    "words_more_than_5 = re.findall(r'\\b[a-zA-Z]{6,}\\b', paragraph);\n",
    "print(\"All words with more than 5 letters are\\n\",words_more_than_5);\n",
    "numbers = re.findall(r'\\b\\d+\\b', paragraph);\n",
    "print(\"\\nAll numbers in text are\\n\",numbers);\n",
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]+\\b', paragraph);\n",
    "print(\"\\nAll capitalized words are\\n\",capitalized_words);\n",
    "\n",
    "alpha_words = re.findall(r'\\b[a-zA-Z]+\\b', paragraph);\n",
    "print(\"\\nWords containing only alphabets (removing digits and special character)\\n\",alpha_words);\n",
    "vowel_words = [word for word in alpha_words if word.lower().startswith(('a', 'e', 'i', 'o', 'u'))];\n",
    "print(\"\\nAll words starting with a vowel are\\n\",vowel_words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c351c8ad-f1cd-4517-ac15-df990a098d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text:\n",
      " One of my favorite topics is technology, especially how it shapes our everyday lives.\n",
      "It’s fascinating to see how innovations like artificial intelligence, smart devices, and cloud computing\n",
      "have transformed the way we communicate, work, and even relax. From voice-controlled assistants that manage\n",
      "our schedules to wearable tech that tracks our health in real time, technology is making life more efficient\n",
      "and connected. I’m especially intrigued by how AI is being used in creative fields like music composition,\n",
      "storytelling, and design.\n",
      "\n",
      "Custom Tokens: ['One', 'of', 'my', 'favorite', 'topics', 'is', 'technology', 'especially', 'how', 'it', 'shapes', 'our', 'everyday', 'lives', 'It’s', 'fascinating', 'to', 'see', 'how', 'innovations', 'like', 'artificial', 'intelligence', 'smart', 'devices', 'and', 'cloud', 'computing', 'have', 'transformed', 'the', 'way', 'we', 'communicate', 'work', 'and', 'even', 'relax', 'From', 'voice', 'controlled', 'assistants', 'that', 'manage', 'our', 'schedules', 'to', 'wearable', 'tech', 'that', 'tracks', 'our', 'health', 'in', 'real', 'time', 'technology', 'is', 'making', 'life', 'more', 'efficient', 'and', 'connected', 'I’m', 'especially', 'intrigued', 'by', 'how', 'AI', 'is', 'being', 'used', 'in', 'creative', 'fields', 'like', 'music', 'composition', 'storytelling', 'and', 'design']\n"
     ]
    }
   ],
   "source": [
    "import re;\n",
    "\n",
    "text = \"\"\"One of my favorite topics is technology, especially how it shapes our everyday lives.\n",
    "It’s fascinating to see how innovations like artificial intelligence, smart devices, and cloud computing\n",
    "have transformed the way we communicate, work, and even relax. From voice-controlled assistants that manage\n",
    "our schedules to wearable tech that tracks our health in real time, technology is making life more efficient\n",
    "and connected. I’m especially intrigued by how AI is being used in creative fields like music composition,\n",
    "storytelling, and design.\"\"\";\n",
    "\n",
    "def custom_tokenize(text):\n",
    "    pattern = r\"\"\"\n",
    "        (?:[a-zA-Z]+(?:['’][a-zA-Z]+)?)     \n",
    "        |(?:\\d+\\.\\d+)                        \n",
    "        |(?:\\d+)                            \n",
    "        |(?:[a-zA-Z]+(?:-[a-zA-Z]+)+)       \n",
    "\"\"\";\n",
    "    tokens = re.findall(pattern, text, re.VERBOSE);\n",
    "    return tokens;\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', '<EMAIL>', text);\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', text);\n",
    "    text = re.sub(r'\\b(?:\\+91\\s?)?\\d{10}\\b', '<PHONE>', text);\n",
    "    text = re.sub(r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b', '<PHONE>', text);\n",
    "    return text;\n",
    "\n",
    "cleaned_text = clean_text(text);\n",
    "print(\"Cleaned Text:\\n\", cleaned_text);\n",
    "\n",
    "tokens = custom_tokenize(cleaned_text);\n",
    "print(\"\\nCustom Tokens:\",tokens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b2cd6-1c3f-4237-afd2-dd48dcf45c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
